# üöÄ Analyse des Consommations √ânerg√©tique en Bretagne

## **Contexte**
Dans ce projet, nous analysons les donn√©es li√©es aux logements en Bretagne pour mieux comprendre leur consommation √©nerg√©tique et identifier des pistes d'am√©lioration. L'objectif est d'√©valuer les co√ªts √©nerg√©tiques et leur relation avec les caract√©ristiques des logements.



##  Pr√©paration des Donn√©es
- **Chargement des donn√©es** :
  - `logements_neufs.csv` : Donn√©es des nouveaux logements.
  - `logements_existants.csv` : Donn√©es des logements existants.
  
  


```python
import pandas as pd
from preprocessing_function import *
import warnings
warnings.filterwarnings('ignore')

logements_neufs = pd.read_csv('data/raw/neufs.csv')
logements_existants = pd.read_csv('data/raw/existents.csv')
```


```python
print(logements_neufs.shape)
print(logements_existants.shape)
```

    (59213, 135)
    (398114, 235)


On peut remarquer que les datasets contiennent √©norm√©ment de donn√©es et de variables. Nous avons supprim√© les variables contenant beaucoup de donn√©es manquantes, 

La colonne **Logement** a √©t√© ajout√© aux dataframes pour distinguer les logements existants des neufs. Nous avons aussi remarqu√© que les logements neufs ne disposent pas de la colonne **Ann√©e_cnstruction** que nous pensons utile pour la mod√©lisation.




```python
import numpy as np

# Pour les anciens
logements_existants["Logement"] = "ancien"
distribution = logements_existants['Ann√©e_construction'].value_counts(normalize=True)

# Remplacer les valeurs manquantes en tirant al√©atoirement bas√© sur la distribution
logements_existants['Ann√©e_construction'] = logements_existants['Ann√©e_construction'].apply(
    lambda x: np.random.choice(distribution.index, p=distribution.values) if pd.isnull(x) else x
)

# Pour les neufs, on cr√©e Ann√©e_construction √† partir de  Date_r√©ception_DPE. 
# La variable Logement est √©galement ajout√© avec la valeur "neuf"
logements_neufs = create_vars(logements_neufs)
```

Nous avons fusionn√© les deux datasets en fonction des colonnes communes. En ce qui concerne la mod√©lisation pr√©dictive, les choix des colonnes ce sont port√©es sur les suivantes:


```python
cols_kept = ['Ann√©e_construction',
            'Code_postal_(brut)',
            'Co√ªt_total_5_usages',
            'Etiquette_DPE',
            'Etiquette_GES',
            'Hauteur_sous-plafond',
            'Logement',
            'Nombre_niveau_logement',
            'Surface_habitable_logement',
            'Type_b√¢timent',
            'N¬∞_d√©partement_(BAN)']
```

Nous les avons pr√©trait√© au travers de la fonction **quali_quanti_preprocessing**. Elle prend en entr√©e les donn√©es s√©par√© en train et test. Nous avons adopt√© cette m√©thode pour √©viter le data leakage.


```python
X_train, X_test = data_split(df, target="Etiquette_DPE", test_size=0.3, stratify=True, seed=0)

orig, new = quali_quanti_preprocessing_classif(X_train, X_test)
```

## Corr√©lation entre les variables 


```python
import seaborn as sns

data_quanti = pd.concat([quanti_train, quanti_test])
data_y = pd.concat([y_train, y_test])
data = pd.concat([data_quanti, data_y], axis=1)
sns.heatmap(data_quanti.corr())
```






    
![png](image\output_1.png)
    


On peut observer qu'il y a peu de corr√©lation entre les variables


```python
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [6, 3]

sns.countplot(x='Etiquette_DPE', data=data, palette='Set3')
plt.title('Distribution des cat√©gories de l\'Etiquette DPE')
plt.show()
```


    
![png](image\output_2.png)
    



```python
sns.scatterplot(x='Surface_habitable_logement', y='Co√ªt_total_5_usages', hue='Etiquette_DPE', data=data, palette='viridis')
plt.title('Co√ªt total vs Surface habitable par Etiquette DPE')
plt.show()
```


    
![png](image\output_3.png)
    


Lorsqu'on croise le Co√ªt total et la Surface habitable par Etiquette DPE, on observe une sorte de corr√©lation qui semble croissante. Cela peut sugg√©rer que les logements plus grands tendent √† avoir des co√ªts √©nerg√©tiques plus √©lev√©s. Ce qui semble tout √† fait normal car une plus grande surface n√©cessite souvent plus d‚Äô√©nergie pour le chauffage, la climatisation, et autres usages, ce qui augmente le co√ªt √©nerg√©tique global.

## Mod√®le de classification 

### Feature selection


```python
feature_names = rf.feature_names_in_[:20]

mdi_importances = pd.Series(
    rf.feature_importances_[:20], index=feature_names
).sort_values(ascending=True)

ax = mdi_importances.plot.barh()
ax.set_title("Random Forest Feature Importances (MDI)")
ax.figure.tight_layout()
```


    
![png](image\output_4.png)
    



```python
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, min_samples_split=5, random_state=0, verbose=1)
rf.fit(X_train_mca, y_train)
y_pred = rf.predict(X_test_mca)
```


```python
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))
```

                  precision    recall  f1-score   support
    
               A       0.97      0.96      0.96      8399
               B       0.91      0.90      0.91      7952
               C       0.94      0.97      0.95     41165
               D       0.90      0.89      0.89     38176
               E       0.87      0.87      0.87     24134
               F       0.85      0.81      0.83     10042
               G       0.89      0.82      0.85      6942
    
        accuracy                           0.91    136810
       macro avg       0.90      0.89      0.90    136810
    weighted avg       0.91      0.91      0.91    136810
    


La pr√©cision globale est de 91%, indiquant que 91% des pr√©dictions totales du mod√®le sont correctes. Il est performant pour les classes majoritaires (A, B, C, D), mais les performances diminuent l√©g√®rement pour les classes minoritaires comme F et G.


```python
new = pd.DataFrame([{"Ann√©e_construction":2024,
                     "Surface_habitable_logement":200,
                     "Co√ªt_total_5_usages":10000,
                     "Etiquette_GES":"B",
                     "Code_postal_(brut)":35660,
                     "Logement":"neuf",
                     "Type_b√¢timent":"maison",
                     "Hauteur_sous-plafond":3,
                     "Nombre_niveau_logement":2
                     }])

from pipeline import Pipeline_classification

print("Pr√©diction de l'√©tiquette DPE'")
Pipeline_classification(new)
```

    Pr√©diction de l'√©tiquette DPE'
    ['B']


Pour cet exemple de donn√©es, le mod√®le de classification a pr√©dit **l'√©tiquette B**.

## Mod√®le de regression


```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=50, min_samples_split=5, max_depth=None, random_state=0, verbose=1)
rf.fit(X_train_mca[vars], y_train)
y_pred = rf.predict(X_test_mca[vars])
```


```python
# Avec DPE
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mse = mean_squared_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse}")
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R¬≤: {r2}")
```

    MSE: 3193454.9583449326
    RMSE: 1787.024050857999
    MAE: 270.5596738731614
    R¬≤: 0.5586152358463896


Les r√©sultats de performance de notre mod√®le de regression montrent que le mod√®le capture une partie importante de la structure des donn√©es, mais il reste une marge d'am√©lioration.


```python
new = pd.DataFrame([{"Ann√©e_construction":2024,
                     "Surface_habitable_logement":20,
                     "Etiquette_DPE":"B",
                     "Code_postal_(brut)":35660,
                     "Logement":"neuf",
                     "Type_b√¢timent":"maison",
                     "Hauteur_sous-plafond":3,
                     "Nombre_niveau_logement":2
                     }])
```

Pour ce exemple le mod√®le de regression a pr√©dit comme conssommation √©nerg√©tique:


```python
from pipeline import Pipeline_regression

print("Pr√©diction de la consommation √©nerg√©tique:")
Pipeline_regression(new)
```

    Pr√©diction de la consommation √©nerg√©tique:
    [354.84852658]

